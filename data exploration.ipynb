{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f2e5b63-5b60-4a0a-b117-39b0967fa65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "235ea1c5-fbba-4488-833f-745a340c045b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForImageClassification\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7768c0d6-60fe-4a81-994e-c6f72140e6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|█| 2.03k/2.03k [00:00<00:00, 2.54MB/s]\n",
      "Downloading model.safetensors: 100%|███████| 94.6M/94.6M [00:10<00:00, 8.98MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model and tokenizer\n",
    "model = AutoModelForImageClassification.from_pretrained(\"jazzmacedo/fruits-and-vegetables-detector-36\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89e7fb6e-514d-4593-aa9b-ac03882e731c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of labels from the model's configuration\n",
    "labels = list(model.config.id2label.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c8de1e5-c2f8-49f9-b0ea-91a2e0378c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the preprocessing transformation\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "277a9dc7-84b2-44b3-af27-5d63d7d3222a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"food.png\"\n",
    "image = cv2.imread(image_path)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "pil_image = Image.fromarray(image)  # Convert NumPy array to PIL image\n",
    "input_tensor = preprocess(pil_image).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d30dbb0-74bc-40fd-be1a-1b29016928d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('output.png', image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86197dcb-af2d-49b5-a5a6-b7860743728e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected label: potato\n"
     ]
    }
   ],
   "source": [
    "# Run the image through the model\n",
    "outputs = model(input_tensor)\n",
    "\n",
    "# Get the predicted label index\n",
    "predicted_idx = torch.argmax(outputs.logits, dim=1).item()\n",
    "\n",
    "# Get the predicted label text\n",
    "predicted_label = labels[predicted_idx]\n",
    "\n",
    "# Print the predicted label\n",
    "print(\"Detected label:\", predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cbc898-47dc-4a6a-8e59-21b1a6451f90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
